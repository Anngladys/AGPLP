{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anngladys/AGPLP/blob/main/Classical_ML_with_Scikit_learn_(Iris_Species_Dataset).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. Load the Iris Species Dataset ---\n",
        "# The Iris dataset is a classic and is included in scikit-learn.\n",
        "# It contains 150 samples of iris flowers, with 4 features and 3 possible species.\n",
        "iris = load_iris()\n",
        "\n",
        "# Create a Pandas DataFrame for easier manipulation and viewing.\n",
        "# The 'data' attribute contains the features, and 'feature_names' are the column names.\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "\n",
        "# Add the target variable (species) to the DataFrame.\n",
        "# 'target' contains numerical labels (0, 1, 2) for the species.\n",
        "# 'target_names' maps these numbers to actual species names (setosa, versicolor, virginica).\n",
        "df['species'] = iris.target\n",
        "df['species_name'] = df['species'].apply(lambda x: iris.target_names[x])\n",
        "\n",
        "print(\"--- Dataset Loaded Successfully ---\")\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "print(\"\\nDataset Info:\")\n",
        "df.info()\n",
        "\n",
        "# --- 2. Preprocess the Data ---\n",
        "\n",
        "# A. Handle Missing Values:\n",
        "# The Iris dataset is clean and typically does not have missing values.\n",
        "# However, in a real-world scenario, you would check and handle them.\n",
        "print(\"\\n--- Checking for Missing Values ---\")\n",
        "print(df.isnull().sum())\n",
        "# If there were missing values, common strategies include:\n",
        "# - Imputation (e.g., df.fillna(df.mean(), inplace=True) for numerical)\n",
        "# - Removing rows/columns (e.g., df.dropna(inplace=True))\n",
        "if df.isnull().sum().sum() == 0:\n",
        "    print(\"No missing values found in the dataset. Good to go!\")\n",
        "else:\n",
        "    print(\"Missing values found. Please handle them before proceeding.\")\n",
        "\n",
        "\n",
        "# B. Encode Labels (if not already numerical):\n",
        "# The 'species' column (iris.target) is already numerically encoded (0, 1, 2).\n",
        "# If the target was categorical strings, we would use LabelEncoder or OneHotEncoder.\n",
        "# Here, we will use the existing numerical 'species' column as our target variable.\n",
        "X = df.drop(['species', 'species_name'], axis=1) # Features (all columns except species and species_name)\n",
        "y = df['species'] # Target (numerical species label)\n",
        "\n",
        "print(\"\\nFeatures (X) shape:\", X.shape)\n",
        "print(\"Target (y) shape:\", y.shape)\n",
        "print(\"Target classes:\", iris.target_names)\n",
        "\n",
        "\n",
        "# --- 3. Split Data into Training and Testing Sets ---\n",
        "# It's crucial to split data to evaluate the model on unseen data.\n",
        "# test_size=0.3 means 30% of data for testing, 70% for training.\n",
        "# random_state ensures reproducibility of the split.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"\\nTraining set size: {len(X_train)} samples\")\n",
        "print(f\"Test set size: {len(X_test)} samples\")\n",
        "print(f\"Distribution of classes in training set:\\n{y_train.value_counts(normalize=True)}\")\n",
        "print(f\"Distribution of classes in test set:\\n{y_test.value_counts(normalize=True)}\")\n",
        "\n",
        "\n",
        "# --- 4. Train a Decision Tree Classifier ---\n",
        "# Initialize the Decision Tree Classifier.\n",
        "# A small max_depth is often good to prevent overfitting on small datasets.\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
        "\n",
        "print(\"\\n--- Training Decision Tree Classifier ---\")\n",
        "# Train the model using the training data.\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "print(\"Decision Tree Classifier trained successfully.\")\n",
        "\n",
        "\n",
        "# --- 5. Evaluate the Model ---\n",
        "# Make predictions on the test set.\n",
        "y_pred = dt_classifier.predict(X_test)\n",
        "\n",
        "print(\"\\n--- Model Evaluation ---\")\n",
        "\n",
        "# A. Accuracy: Proportion of correctly classified samples.\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# B. Precision: Ability of the classifier not to label as positive a sample that is negative.\n",
        "# 'macro' calculates metrics for each label and takes unweighted mean.\n",
        "# 'weighted' calculates metrics for each label and takes weighted average by support.\n",
        "# 'none' returns score for each class.\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "print(f\"Precision (weighted): {precision:.4f}\")\n",
        "\n",
        "# C. Recall: Ability of the classifier to find all the positive samples.\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "print(f\"Recall (weighted): {recall:.4f}\")\n",
        "\n",
        "# D. Classification Report: Provides a comprehensive report of precision, recall,\n",
        "# f1-score, and support for each class.\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n",
        "\n",
        "# --- Optional: Visualize the Decision Tree (requires graphviz) ---\n",
        "# This part is commented out by default as it requires additional installations\n",
        "# If you want to visualize, uncomment the lines below and run:\n",
        "# pip install graphviz\n",
        "# pip install scikit-learn[tree]\n",
        "# import graphviz\n",
        "# from sklearn.tree import export_graphviz\n",
        "#\n",
        "# dot_data = export_graphviz(dt_classifier, out_file=None,\n",
        "#                            feature_names=iris.feature_names,\n",
        "#                            class_names=iris.target_names,\n",
        "#                            filled=True, rounded=True,\n",
        "#                            special_characters=True)\n",
        "# graph = graphviz.Source(dot_data)\n",
        "# graph.render(\"iris_decision_tree\", view=True) # Saves to a file and opens it\n",
        "\n",
        "print(\"\\n--- Analysis Complete ---\")\n",
        "print(\"This script demonstrates data preprocessing, decision tree training, and evaluation for the Iris dataset.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Dataset Loaded Successfully ---\n",
            "First 5 rows of the dataset:\n",
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
            "0                5.1               3.5                1.4               0.2   \n",
            "1                4.9               3.0                1.4               0.2   \n",
            "2                4.7               3.2                1.3               0.2   \n",
            "3                4.6               3.1                1.5               0.2   \n",
            "4                5.0               3.6                1.4               0.2   \n",
            "\n",
            "   species species_name  \n",
            "0        0       setosa  \n",
            "1        0       setosa  \n",
            "2        0       setosa  \n",
            "3        0       setosa  \n",
            "4        0       setosa  \n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 6 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   sepal length (cm)  150 non-null    float64\n",
            " 1   sepal width (cm)   150 non-null    float64\n",
            " 2   petal length (cm)  150 non-null    float64\n",
            " 3   petal width (cm)   150 non-null    float64\n",
            " 4   species            150 non-null    int64  \n",
            " 5   species_name       150 non-null    object \n",
            "dtypes: float64(4), int64(1), object(1)\n",
            "memory usage: 7.2+ KB\n",
            "\n",
            "--- Checking for Missing Values ---\n",
            "sepal length (cm)    0\n",
            "sepal width (cm)     0\n",
            "petal length (cm)    0\n",
            "petal width (cm)     0\n",
            "species              0\n",
            "species_name         0\n",
            "dtype: int64\n",
            "No missing values found in the dataset. Good to go!\n",
            "\n",
            "Features (X) shape: (150, 4)\n",
            "Target (y) shape: (150,)\n",
            "Target classes: ['setosa' 'versicolor' 'virginica']\n",
            "\n",
            "Training set size: 105 samples\n",
            "Test set size: 45 samples\n",
            "Distribution of classes in training set:\n",
            "species\n",
            "1    0.333333\n",
            "0    0.333333\n",
            "2    0.333333\n",
            "Name: proportion, dtype: float64\n",
            "Distribution of classes in test set:\n",
            "species\n",
            "2    0.333333\n",
            "1    0.333333\n",
            "0    0.333333\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "--- Training Decision Tree Classifier ---\n",
            "Decision Tree Classifier trained successfully.\n",
            "\n",
            "--- Model Evaluation ---\n",
            "Accuracy: 0.9333\n",
            "Precision (weighted): 0.9444\n",
            "Recall (weighted): 0.9333\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        15\n",
            "  versicolor       1.00      0.80      0.89        15\n",
            "   virginica       0.83      1.00      0.91        15\n",
            "\n",
            "    accuracy                           0.93        45\n",
            "   macro avg       0.94      0.93      0.93        45\n",
            "weighted avg       0.94      0.93      0.93        45\n",
            "\n",
            "\n",
            "--- Analysis Complete ---\n",
            "This script demonstrates data preprocessing, decision tree training, and evaluation for the Iris dataset.\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-g6fyOrxhFF",
        "outputId": "0378e1f3-8ed8-4039-f3fd-15dc270fbf15"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}